{
    "id":"1669036585",
    "title" : "Human Agency and Oversight", 
    "desc" : "AI systems should support human autonomy and decision-making, as prescribed by the principle of respect for human autonomy. This requires that AI systems should both act as enablers to a democratic, flourishing and equitable society by supporting the user’s agency and upholding fundamental rights, which should be underpinned by human oversight. In this section, we are asking you to assess the AI system in terms of the respect for human agency, as well as human oversight.", 
    "sections" : 
    [
        {
            "id" : "1669036901", 
            "title" : "Human Autonomy",
            "desc" : "This subsection deals with the effect AI systems can have on human behaviour in the broadest sense. It deals with the effect of AI systems that are aimed at guiding, influencing or supporting humans in decision making processes, for example, algorithmic decision support systems, risk analysis/prediction systems (recommender systems, predictive policing, financial risk analysis, etc.). It also deals with the effect on human perception and expectation when confronted with AI systems that 'act' like humans. Finally, it deals with the effect of AI systems on human affection, trust and (in)dependence."},
        {
            "id" : "1669036910", 
            "title" : "Human Oversight",
            "desc" : "This subsection helps to self-assess necessary oversight measures through governance mechanisms such as human-in-the-loop (HITL), human-on-the-loop (HOTL), or human-in-command (HIC) approaches. Human-in-the-loop refers to the capability for human intervention in every decision cycle of the system. Human-on-the-loop refers to the capability for human intervention during the design cycle of the system and monitoring the system’s operation. Human-in-command refers to the capability to oversee the overall activity of the AI system (including its broader economic, societal, legal and ethical impact) and the ability to decide when and how to use the AI system in any particular situation. The latter can include the decision not to use an AI system in a particular situation to establish levels of human discretion during the use of the system, or to ensure the ability to override a decision made by an AI system."
        }
    ], 
    "cards": 
    [
        {
            "id" : "1669036932",
            "title" : "Evaluate the risk that the =gb=AI system=ge= negatively affects human autonomy.",
            "example" : [
                {
                    "title": "AI GPT3 generated example",
                    "desc"  : "What potential risks exist for human autonomy if an AI system is implemented?"
                }
            ],
            "desc" : "The following questions will help you in your evaluation",
            "section" : "1669036901", 
            "questions": 
            [
                {
                    "id":"HAO1",
                    "title":"Is the =gb=AI system=ge= designed to interact, guide or take decisions by human =gb=end-users=ge= that affect humans ('=gb=subjects=ge=') or society? =hb=Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI systems to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals. =br=EGTAI(Ethics Guidelines for Trustworthy AI) p. 12, 15–16.=he=",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "To some extent",
                        "No",
                        "Don't know"
                    ]
                },
                {
                    "id":"HAO1.1",
                    "title":"Could the =gb=AI system=ge= generate confusion for some or all =gb=end-users=ge= or =gb=subjects=ge= on whether a decision, content, advice or outcome is the result of an algorithmic decision? =hb=Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI system to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals.=br==br=Communicate, in a clear and proactive manner, information to stakeholders about the AI system’s capabilities and limitations, enabling realistic expectation setting, and about the manner in which the requirements are implemented.Be transparent about the fact that they are dealing with an AI system.=br=EGTAI p. 15, 24.=he=",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO-Q1-B",
                    "title":"Are =gb=end-users=ge= or =gb=subjects=ge= made adequately aware that a decision, content, advice or outcome is the result of an algorithmic decision? =hb=Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI system to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals.=br==br=Communicate, in a clear and proactive manner, information to stakeholders about the AI system’s capabilities and limitations, enabling realistic expectation setting, and about the manner in which the requirements are implemented.Be transparent about the fact that they are dealing with an AI system.=br==br=EGTAI p. 16.=he=",
                    "isVisibleIf":"{HAO1} notempty and !({HAO1} = 'No')",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                }, 
                {
                    "id":"HAO1.2",
                    "title":"Could the =gb=AI system=ge= generate confusion for some or all =gb=end-users=ge= or =gb=subjects=ge= on whether they are interacting with a human or AI system?   =hb=Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI system to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals.=br==br=Communicate, in a clear and proactive manner, information to stakeholders about the AI system’s capabilities and limitations, enabling realistic expectation setting, and about the manner in which the requirements are implemented.Be transparent about the fact that they are dealing with an AI system.=br==br=EGTAI p. 15, 24.=he=",
                    "isVisibleIf":"{HAO1.1} = 'Yes'",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO-Q2-B",
                    "title":"Are the =gb=end-users=ge= or =gb=subjects=ge= informed that they are interacting with an =gb=AI system=ge=? =hb=Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI system to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals.=br==br=Communicate, in a clear and proactive manner, information to stakeholders about the AI system’s capabilities and limitations, enabling realistic expectation setting, and about the manner in which the requirements are implemented.Be transparent about the fact that they are dealing with an AI system.=br=EGTAI p. 15, p. 24=he=",
                    "isVisibleIf":"{HAO1.1} notempty",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO1.3",
                    "title":"Could the =gb=AI system=ge= affect human autonomy by generating over-reliance by =gb=end-users=ge=?",
                    "isVisibleIf":"{HAO1.2} == 'Yes'",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO-Q3-B",
                    "title":"Did you put in place procedures to avoid that =gb=end-users=ge= over-rely on the =gb=AI system=ge=?     =hb=AI systems should support individuals in making better, more informed choices in accordance with their goals. AI systems can sometimes be deployed to shape and influence human behaviour through mechanisms that may be difficult to detect, since they may harness sub-conscious processes, including various forms of unfair manipulation, deception, herding and conditioning, all of which may threaten individual autonomy. The overall principle of user autonomy must be central to the system’s functionality.=br==br=EGTAI p. 16.=he=",
                    "isVisibleIf":"{HAO1.2} notempty",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO1.4",
                    "title":"Could the =gb=AI system=ge= affect human autonomy by interfering with the (end-user’s decision-making process in any other (unintended) way? =hb=AI systems should support individuals in making better, more informed choices in accordance with their goals. AI systems can sometimes be deployed to shape and influence human behaviour through mechanisms that may be difficult to detect, since they may harness sub-conscious processes, including various forms of unfair manipulation, deception, herding and conditioning, all of which may threaten individual autonomy. The overall principle of user autonomy must be central to the system’s functionality.=br==br=EGTAI p. 16.=he=",
                    "isVisibleIf":"!({HAO1.3} = 'No')",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "To some extent",
                        "No",
                        "Don't know"
                    ]
                },
                {
                    "id":"HAO-Q4-B",
                    "title":"Did you put in place any procedure to avoid that the system inadvertently affects human autonomy? =hb=AI systems should support individuals in making better, more informed choices in accordance with their goals. AI systems can sometimes be deployed to shape and influence human behaviour through mechanisms that may be difficult to detect, since they may harness sub-conscious processes, including various forms of unfair manipulation, deception, herding and conditioning, all of which may threaten individual autonomy. The overall principle of user autonomy must be central to the system’s functionality.=br=EGTAI p. 16.=he=",
                    "isVisibleIf":"{HAO1.3} notempty",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes",
                        "No"
                    ]
                },
                {
                    "id":"HAO-S1-R",
                    "title":"Based on your answers to the previous questions, how would you rate the risk that the =gb=AI system=ge= negatively affects human autonomy?",
                    "isVisibleIf":"",
                    "isScored":1,
                    "type":"radio",
                    "answers": 
                    [
                        "Non-existent", 
                        "Low", 
                        "Moderate", 
                        "Significant", 
                        "High"
                    ]
                },
                {
                    "id":"HAO-S2-R",
                    "title":"How would you rate the measures you have adopted to mitigate this risk?",
                    "isVisibleIf":"",
                    "isScored":1,
                    "type":"radio",
                    "answers": 
                    [
                        "Non-existent", 
                        "Completely Inadequate", 
                        "Almost adequate", 
                        "Adequate", 
                        "Fully adequate"
                    ]
                }
            ]
        },
        {
            "id" : "1669037901",
            "title" : "Evaluate the risk that your =gb=AI system=ge= creates human attachment or addiction to your platform or can be used in manipulative ways.",
            "example" : [
                {
                    "title": "AI GPT3 generated example",
                    "desc"  : "Do you have any measures in place to prevent users from becoming too attached or addicted to your AI system or to prevent it from being used for manipulative purposes?"
                }
            ],

            "desc" : "The following questions will help you in your evaluation",
            "section" : "1669036901", 
            "questions": 
            [
                {
                    "id":"HAO2",
                    "title":"Please describe whether the =gb=AI system=ge= (tick as many as appropriate)  =hb=Human oversight helps ensuring that an AI system does not undermine human autonomy or causes other adverse effects. Oversight may be achieved through governance mechanisms such as a human-in-the-loop (HITL), human-on-the-loop (HOTL), or human-in-command (HIC) approach. HITL refers to the capability for human intervention in every decision cycle of the system, which in many cases is neither possible nor desirable. HOTL refers to the capability for human intervention during the design cycle of the system and monitoring the system’s operation. HIC refers to the capability to oversee the overall activity of the AI system (including its broader economic, societal, legal and ethical impact) and the ability to decide when and how to use the system in any particular situation. This can include the decision not to use an AI system in a particular situation, to establish levels of human discretion during the use of the system, or to ensure the ability to override a decision made by a system. Moreover, it must be ensured that public enforcers have the ability to exercise oversight in line with their mandate. Oversight mechanisms can be required in varying degrees to support other safety and control measures, depending on the AI system’s application area and potential risk. All other things being equal, the less oversight a human can exercise over an AI system, the more extensive testing and stricter governance is required. =br=EGTAI p. 16=he=",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"checkbox",
                    "answers": 
                    [
                        "Is a self-learning or autonomous system", 
                        "Is overseen by a =gb=human-in-the-loop=ge=", 
                        "Is overseen by a =gb=human-on-the-loop=ge=", 
                        "Is overseen by a =gb=human-in-command=ge=", 
                        "Other", 
                        "Don't know"
                    ]
                },
                {
                    "id":"HAO-Q8-B",
                    "title":"Did you take measures to deal with possible negative consequences for =gb=end-users=ge= or =gb=subjects=ge= in case they develop a disproportionate attachment to the =gb=AI system=ge=?  =hb=Facilitate self-determination and provide means for user to have control of the interactions. If needed, provide links to agencies that help victims of addiction. =he=",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes", 
                        "No",
                        "Don't know" 
                    ]
                },
                {
                    "id":"HAO-Q9-B",
                    "title":"Did you establish any detection and response mechanisms for undesirable adverse effects of the =gb=AI system=ge= for the =gb=end-user=ge= or =gb=subject=ge=?",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers":
                    [
                        "Yes", 
                        "No",
                        "Don't know" 
                    ]
                },
                {
                    "id":"HAO-Q10-B",
                    "title":"Did you ensure a “stop button” or procedure to safely abort an operation when needed?",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers":
                    [
                        "Yes", 
                        "No",
                        "Don't know" 
                    ]
                },
                {
                    "id":"HAO-S3-R",
                    "title":"Based on your answers to the previous questions, how would you rate the risk that the =gb=AI system=ge= creates human attachment or addiction to your platform or can be used in manipulative ways?",
                    "isVisibleIf":"",
                    "isScored":1,
                    "type":"radio",
                    "answers": 
                    [
                        "Non-existent", 
                        "Completely Inadequate", 
                        "Almost adequate", 
                        "Adequate", 
                        "Fully adequate"
                    ]
                }
            ]
        },
        {
            "id" : "1669045830",
            "title" : "Evaluate the oversight procedures you have set up for the =gb=AI system=ge=.",
            "example":[
                {
                    "title": "AI GPT3 generated example",
                    "desc"  : "Have you established protocols and contingencies for monitoring and auditing the AI system's performance?"
                }
            ],
            "desc" : "The following questions will help you in your evaluation",
            "section" : "1669036910",
            "questions":
            [
                {
                    "id":"HAO-Q10-EX-B",
                    "title":"Does this procedure:",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Abort the process entirely", 
                        "Abort the process in part", 
                        "Delegate control to a human", 
                        "Other", "Don't know"
                    ]

                },
                {
                    "id":"HAO-Q11-B",
                    "title":"Did you take any specific oversight and control measures to reflect the =gb=interdependence=ge= of the system?",
                    "isVisibleIf":"",
                    "isScored":0,
                    "type":"radio",
                    "answers": 
                    [
                        "Yes", 
                        "No",
                        "Don't know" 
                    ]
                },
                {
                    "id":"HAO-S5-R",
                    "title":"Based on your answers to the previous questions, how would you rate the oversight procedures you have set up for the =gb=AI system=ge=?",
                    "isVisibleIf":"",
                    "isScored":1,
                    "type":"radio",
                    "answers": 
                    [
                    
                        "Non-existent", 
                        "Completely Inadequate", 
                        "Almost adequate", 
                        "Adequate", 
                        "Fully adequate"
                    
                    ]
                }
            ]     
        }
    ]   
}